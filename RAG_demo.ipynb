{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciQuery: Advanced RAG System using LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.run_pipeline_manager import RAGPipelineManager\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG with semantic chunking and fusion retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== LLM llama3.1:latest is loaded successfully using the provider ollama\n",
      "============================== Embedding mixedbread-ai/mxbai-embed-large-v1 is loaded successfully using the provider huggingface\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:SEND Error: Host unreachable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/pdf_documents\n",
      "Found 840 total number of pages from the 63 pdf files\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Initialize RAGPipelineManager\n",
    "rag_manager_semantic = RAGPipelineManager(document_parsing_method=\"simple\",node_parsing_method=\"semantic\", retrieval_type = \"fusion_retrieval\")\n",
    "# Create the RAG pipeline\n",
    "query_pipeline_s = rag_manager_semantic.create_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, steps = query_pipeline_s.run_with_intermediates(topic=\"explain word embeddings\")\n",
    "\n",
    "print(output.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with semantic chunk and simple retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RAGPipelineManager\n",
    "rag_manager_semantic_simple = RAGPipelineManager(document_parsing_method=\"simple\",node_parsing_method=\"semantic\", retrieval_type = \"simple\")\n",
    "# Create the RAG pipeline\n",
    "query_pipeline_ss = rag_manager_semantic_simple.create_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, steps = query_pipeline_ss.run_with_intermediates(topic=\"explain word embeddings\")\n",
    "\n",
    "print(output.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with sentence window chunking and small-to-big retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_manager_sent_window = RAGPipelineManager(document_parsing_method=\"simple\",node_parsing_method=\"sentence_window\", retrieval_type=\"small_to_big\")\n",
    "\n",
    "# Create the RAG pipelines\n",
    "query_pipeline_sw = rag_manager_sent_window.create_pipeline(verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output, steps = query_pipeline_sw.run_with_intermediates(topic=\"explain word embeddings\")\n",
    "\n",
    "print(output.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in steps[\"retriever\"].outputs[\"output\"]:\n",
    "    print(f'text:{x.text}')\n",
    "    print(f'id {x.id_}')\n",
    "    print(f'page num {x.metadata[\"page_label\"]}, file_name {x.metadata[\"file_name\"]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with hierarchical chunking and small-to-big retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_manager_hr = RAGPipelineManager(document_parsing_method=\"simple\",node_parsing_method=\"hierarchical\", retrieval_type=\"small_to_big\")\n",
    "\n",
    "# Create the RAG pipeline\n",
    "query_pipeline_hr = rag_manager_hr.create_pipeline(verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output, steps = query_pipeline_hr.run_with_intermediates(topic=\"explain word embeddings\")\n",
    "\n",
    "print(output.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in steps[\"retriever\"].outputs[\"output\"]:\n",
    "    print(f'text:{x.text}')\n",
    "    print(f'id {x.id_}')\n",
    "    print(f'page num {x.metadata[\"page_label\"]}, file_name {x.metadata[\"file_name\"]}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unstructured_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
